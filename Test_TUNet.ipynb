{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:30.170356Z",
     "start_time": "2024-12-19T15:18:24.094500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "#sys.path.append('C:/Users/vodou/miniconda3/envs/aml/Lib/site-packages')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss, Dropout, Softmax, Linear, Conv2d, LayerNorm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "import math\n",
    "import functools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from einops import rearrange"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:32.609719Z",
     "start_time": "2024-12-19T15:18:32.110684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Not necessary to below notebook\n",
    "sys.path.append('C:/Users/vodou/Documents/Python Scripts')\n",
    "from pushover_notifier import PushoverNotifier\n",
    "\n",
    "notifier = PushoverNotifier(app_name=\"Task 3 (AML)\")\n",
    "notifier.redirect_print_to_pushover()"
   ],
   "id": "c60043e4ff332803",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:33.805591Z",
     "start_time": "2024-12-19T15:18:33.791560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNNEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim=512, hidden_dims=[32, 64, 128, 256, 512, 1024]):\n",
    "\n",
    "        super(CNNEncoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_dim, out_channels=hidden_dims[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=hidden_dims[0], out_channels=hidden_dims[0], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=hidden_dims[0], out_channels=hidden_dims[1], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=hidden_dims[1], out_channels=hidden_dims[1], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=hidden_dims[1], out_channels=hidden_dims[2], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=hidden_dims[2], out_channels=hidden_dims[2], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(in_channels=hidden_dims[2], out_channels=hidden_dims[3], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(in_channels=hidden_dims[3], out_channels=hidden_dims[3], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv9 = nn.Conv2d(in_channels=hidden_dims[3], out_channels=hidden_dims[4], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv10 = nn.Conv2d(in_channels=hidden_dims[4], out_channels=hidden_dims[4], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(in_channels=hidden_dims[4], out_channels=output_dim, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(in_channels=output_dim, out_channels=output_dim, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        r1 = x\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        r2 = x\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "\n",
    "        r3 = x\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "\n",
    "        r4 = x\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.relu(self.conv10(x))\n",
    "\n",
    "        r5 = x\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "\n",
    "        return x, r1, r2, r3, r4, r5"
   ],
   "id": "ff66b2eaf9c2367a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:35.205922Z",
     "start_time": "2024-12-19T15:18:35.189170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNNDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_dim=1, input_dim=512, hidden_dims=[512, 256, 128, 64, 32]):\n",
    "\n",
    "        super(CNNDecoder, self).__init__()\n",
    "\n",
    "        self.convt1 = nn.ConvTranspose2d(in_channels=input_dim, out_channels=hidden_dims[0], kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=hidden_dims[0]*2, out_channels=hidden_dims[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=hidden_dims[0], out_channels=hidden_dims[0], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.convt2 = nn.ConvTranspose2d(in_channels=hidden_dims[0], out_channels=hidden_dims[1], kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=hidden_dims[1]*2, out_channels=hidden_dims[1], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=hidden_dims[1], out_channels=hidden_dims[1], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.convt3 = nn.ConvTranspose2d(in_channels=hidden_dims[1], out_channels=hidden_dims[2], kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=hidden_dims[2]*2, out_channels=hidden_dims[2], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=hidden_dims[2], out_channels=hidden_dims[2], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.convt4 = nn.ConvTranspose2d(in_channels=hidden_dims[2], out_channels=hidden_dims[3], kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(in_channels=hidden_dims[3]*2, out_channels=hidden_dims[3], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(in_channels=hidden_dims[3], out_channels=hidden_dims[3], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.convt5 = nn.ConvTranspose2d(in_channels=hidden_dims[3], out_channels=hidden_dims[4], kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv9 = nn.Conv2d(in_channels=hidden_dims[4]*2, out_channels=hidden_dims[4], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv10 = nn.Conv2d(in_channels=hidden_dims[4], out_channels=hidden_dims[4], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(in_channels=hidden_dims[4], out_channels=output_dim, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x, r1, r2, r3, r4, r5):\n",
    "\n",
    "        x = self.convt1(x)\n",
    "        x = torch.cat((r5, x), dim=1)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        m1 = x\n",
    "\n",
    "        x = self.convt2(x)\n",
    "        x = torch.cat((r4, x), dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        m2 = x\n",
    "\n",
    "        x = self.convt3(x)\n",
    "        x = torch.cat((r3, x), dim=1)\n",
    "\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "\n",
    "        m3 = x\n",
    "\n",
    "        x = self.convt4(x)\n",
    "        x = torch.cat((r2, x), dim=1)\n",
    "\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "\n",
    "        m4 = x\n",
    "\n",
    "        x = self.convt5(x)\n",
    "        x = torch.cat((r1, x), dim=1)\n",
    "\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.relu(self.conv10(x))\n",
    "\n",
    "        x = self.conv11(x)\n",
    "\n",
    "        return x, m1, m2, m3, m4"
   ],
   "id": "7ba9eb493439f55f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:35.948265Z",
     "start_time": "2024-12-19T15:18:35.940319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=1):\n",
    "\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.cnn_encoder = CNNEncoder(input_dim=input_dim)\n",
    "        self.cnn_decoder = CNNDecoder()\n",
    "\n",
    "        #self.transformer_encoder = TransformerEncoder(embed_dim=512, hidden_dim=512)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x, r1, r2, r3, r4, r5 = self.cnn_encoder(x)\n",
    "        #x = self.transformer_encoder(x)\n",
    "        x, m1, m2, m3, m4 = self.cnn_decoder(x, r1, r2, r3, r4, r5)\n",
    "\n",
    "        return x"
   ],
   "id": "683268fae5fa579e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:36.676659Z",
     "start_time": "2024-12-19T15:18:36.516328Z"
    }
   },
   "cell_type": "code",
   "source": "unet = UNet()",
   "id": "2f59d18b0008787d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:37.290663Z",
     "start_time": "2024-12-19T15:18:37.281514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TensorSegmentationDataset(Dataset):\n",
    "    def __init__(self, images, masks, transform=None):\n",
    "\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            # Apply the transform to both the image and mask\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "\n",
    "        return image, mask"
   ],
   "id": "7e96a009f25c4768",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:37.970839Z",
     "start_time": "2024-12-19T15:18:37.959372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BCEWithDiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, pos_weight=None, size_penalty=0.01):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        self.dice = DiceLoss()\n",
    "        self.size_penalty = size_penalty\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        bce_loss = self.bce(outputs, targets)\n",
    "        dice_loss = self.dice(outputs, targets)\n",
    "        size_penalty = self.size_penalty * outputs.sigmoid().sum(dim=(1, 2, 3)).mean()\n",
    "        return bce_loss + dice_loss #+ size_penalty"
   ],
   "id": "1c1327a918b8a81d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:38.749541Z",
     "start_time": "2024-12-19T15:18:38.738816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiceLoss(nn.Module):\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)  # Convert logits to probabilities\n",
    "        intersection = (inputs * targets).sum(dim=(2, 3))  # Overlap\n",
    "        dice = (2. * intersection + smooth) / (inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3)) + smooth)\n",
    "        return 1 - dice.mean()"
   ],
   "id": "ec3185e47526c6a8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:39.558129Z",
     "start_time": "2024-12-19T15:18:39.553762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_pos_weight(masks):\n",
    "    total_pixels = torch.numel(masks)\n",
    "    positive_pixels = (masks == 1).sum().item()\n",
    "    negative_pixels = (masks == 0).sum().item()\n",
    "    pos_weight = negative_pixels / (positive_pixels + 1e-6)  # Avoid division by zero\n",
    "    return torch.tensor(pos_weight, dtype=torch.float)"
   ],
   "id": "3d1149c57ef223b6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:40.173649Z",
     "start_time": "2024-12-19T15:18:40.165487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, dataloader, optimizer='adam', loss_fn=nn.BCEWithLogitsLoss(), device='cpu', num_epochs=20):\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        optimizer=optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)  # Move images to GPU/CPU\n",
    "            masks = masks.to(device)   # Move masks to GPU/CPU\n",
    "\n",
    "            # For BCEWithLogitsLoss, masks must be float (not long/int)\n",
    "            masks = masks.float()# if isinstance(loss_fn, nn.BCEWithLogitsLoss) else masks.long()\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)  # Predicted masks\n",
    "            loss = loss_fn(outputs, masks)  # Compute the loss\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "\n",
    "    return model\n"
   ],
   "id": "e00279106782db19",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:41.026035Z",
     "start_time": "2024-12-19T15:18:41.020470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, X_test):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictions = model(X_test)\n",
    "\n",
    "        # Apply sigmoid to convert logits to probabilities (for binary segmentation)\n",
    "        predictions = torch.sigmoid(predictions)\n",
    "\n",
    "        # Convert to binary mask with a threshold of 0.5 (for binary classification)\n",
    "        predicted_masks = (predictions > 0.5).float()\n",
    "\n",
    "    return predicted_masks"
   ],
   "id": "61fea865d8234b2c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:41.738719Z",
     "start_time": "2024-12-19T15:18:41.733422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def iou(pred_mask, gt_mask):\n",
    "    intersection = torch.sum(pred_mask * gt_mask)\n",
    "    union = torch.sum(pred_mask) + torch.sum(gt_mask) - intersection\n",
    "    return intersection / union if union != 0 else torch.tensor(0.0)"
   ],
   "id": "6c1664f43f3a7e1a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:18:45.930070Z",
     "start_time": "2024-12-19T15:18:43.624203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import importlib\n",
    "from skimage import exposure\n",
    "from skimage.transform import rotate\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "42c8cff4faea7835",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:19:01.355497Z",
     "start_time": "2024-12-19T15:19:01.208814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.append('C:/Users/vodou/Documents/Python Scripts')\n",
    "\n",
    "import prog_tools as pt\n",
    "import computer_interface as ci\n",
    "import elastic\n",
    "\n",
    "import task3 as helper"
   ],
   "id": "525d844db5b09982",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\asyncio\\base_events.py\", line 640, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\asyncio\\base_events.py\", line 1992, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\vodou\\AppData\\Local\\Temp\\ipykernel_22904\\55562028.py\", line 5, in <module>\n",
      "    import elastic\n",
      "  File \"C:\\Users/vodou/Documents/Python Scripts\\elastic.py\", line 1, in <module>\n",
      "    import elasticdeform\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\elasticdeform\\__init__.py\", line 1, in <module>\n",
      "    from .deform_grid import deform_grid, deform_grid_gradient, deform_random_grid\n",
      "  File \"C:\\Users\\vodou\\miniconda3\\envs\\aml\\Lib\\site-packages\\elasticdeform\\deform_grid.py\", line 4, in <module>\n",
      "    from . import _deform_grid\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\envs\\aml\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(attr_name)\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001B[39;00m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001B[39;00m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001B[39;00m\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001B[39;00m\n\u001B[0;32m     43\u001B[0m     sys\u001B[38;5;241m.\u001B[39mstderr\u001B[38;5;241m.\u001B[39mwrite(msg \u001B[38;5;241m+\u001B[39m tb_msg)\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[0;32m     46\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(_multiarray_umath, attr_name, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mImportError\u001B[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mprog_tools\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpt\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#import computer_interface as ci\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01melastic\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtask3\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mhelper\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Users/vodou/Documents/Python Scripts\\elastic.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01melasticdeform\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeform_random_grid\u001B[39m(\u001B[38;5;28mlist\u001B[39m, sigma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, points\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m):\n\u001B[0;32m      4\u001B[0m     deformed_frame, deformed_mask \u001B[38;5;241m=\u001B[39m elasticdeform\u001B[38;5;241m.\u001B[39mdeform_random_grid(\u001B[38;5;28mlist\u001B[39m, sigma\u001B[38;5;241m=\u001B[39msigma, points\u001B[38;5;241m=\u001B[39mpoints)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\aml\\Lib\\site-packages\\elasticdeform\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeform_grid\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deform_grid, deform_grid_gradient, deform_random_grid\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\aml\\Lib\\site-packages\\elasticdeform\\deform_grid.py:4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mndimage\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _deform_grid\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeform_random_grid\u001B[39m(X, sigma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m, points\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconstant\u001B[39m\u001B[38;5;124m'\u001B[39m, cval\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m,\n\u001B[0;32m      7\u001B[0m                        crop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, prefilter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m      8\u001B[0m                        affine\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, rotate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, zoom\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m      9\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;124;03m    Elastic deformation with a random deformation grid\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;124;03m    deform_grid : for a full description of the parameters.\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_data = helper.load_zipped_pickle(\"train.pkl\")\n",
    "test_data = helper.load_zipped_pickle(\"test.pkl\")"
   ],
   "id": "acd7c70156411869",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# remove all amateur data\n",
    "train_data = [item for item in train_data if item.get('dataset') != 'amateur']"
   ],
   "id": "48b80173266c1bba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_names, train_videos, train_masks = helper.preprocess_train_data(train_data)\n",
    "test_names, test_videos = helper.preprocess_test_data(test_data)"
   ],
   "id": "8eb4f161664cd274",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prev = test_names[0]\n",
    "nb = 1\n",
    "nb_name = 0\n",
    "name_and_seq = []\n",
    "for name in test_names:\n",
    "    if name != prev:\n",
    "        name_and_seq.append((prev, nb_name))\n",
    "        nb += 1\n",
    "        nb_name = 0\n",
    "        prev = name\n",
    "    nb_name += 1\n",
    "\n",
    "name_and_seq.append((prev, nb_name))\n",
    "name_and_seq"
   ],
   "id": "4876a7743013762d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_segmented_frames(video_frames, mask_frames):\n",
    "    \"\"\"\n",
    "    Extracts video frames that have a segmented mitral valve labeled.\n",
    "\n",
    "    Parameters:\n",
    "    - video_frames: List of 3D numpy arrays (H x W x 1) representing video frames.\n",
    "    - mask_frames: List of 3D numpy arrays (H x W x 1) representing segmentation masks.\n",
    "\n",
    "    Returns:\n",
    "    - segmented_frames: List of video frames where the mitral valve is labeled.\n",
    "    - corresponding_masks: List of masks for the extracted frames.\n",
    "    \"\"\"\n",
    "    segmented_frames = []\n",
    "    corresponding_masks = []\n",
    "\n",
    "    for video_frame, mask_frame in zip(video_frames, mask_frames):\n",
    "        # Check if the mask contains any non-zero values (segmented region exists)\n",
    "        if np.any(mask_frame):\n",
    "            segmented_frames.append(video_frame)\n",
    "            corresponding_masks.append(mask_frame)\n",
    "\n",
    "    return segmented_frames, corresponding_masks"
   ],
   "id": "13af703686b250dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_frames, train_masks = extract_segmented_frames(train_videos, train_masks)",
   "id": "7302700c75dad4b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "target_size = (256, 256)",
   "id": "e318a5bb3a80dadd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resized_train_frames = [cv2.resize(frame, target_size, interpolation=cv2.INTER_NEAREST) for frame in train_frames]\n",
    "resized_test_frames = [cv2.resize(frame, target_size, interpolation=cv2.INTER_NEAREST) for frame in test_videos]"
   ],
   "id": "a120666fea1a3636",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resized_train_masks = []\n",
    "\n",
    "# mask frames are in int32, which isn't compatible with the cv2.resize function, so we need to convert them to uint8 first\n",
    "for i, mask in enumerate(train_masks):\n",
    "\n",
    "    if mask.dtype != np.uint8:\n",
    "        mask = mask.astype(np.uint8)\n",
    "\n",
    "    resized_mask = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "    resized_train_masks.append(resized_mask)"
   ],
   "id": "ffad2dad03901dfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resized_train_frames = np.expand_dims(resized_train_frames, axis=-1)\n",
    "resized_train_masks = np.expand_dims(resized_train_masks, axis=-1)"
   ],
   "id": "3dc72c6b358700eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "equalised_train = []\n",
    "equalised_test = []\n",
    "\n",
    "for i in range(len(resized_train_frames)):\n",
    "    temp_array = []\n",
    "    for j in range(len(resized_train_frames[i])):\n",
    "        temp_array.append(exposure.equalize_hist(resized_train_frames[i][j]))\n",
    "    equalised_train.append(temp_array)\n",
    "\n",
    "for i in range(len(resized_test_frames)):\n",
    "    equalised_test.append(exposure.equalize_hist(resized_test_frames[i]))"
   ],
   "id": "20e8d5108826d761",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "normalised_train = []\n",
    "normalised_test = []\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "for i in range(len(equalised_train)):\n",
    "    temp_array = []\n",
    "    for j in range(len(equalised_train[i])):\n",
    "        temp_array.append(scaler.fit_transform(equalised_train[i][j]))\n",
    "    normalised_train.append(temp_array)\n",
    "\n",
    "for i in range(len(equalised_test)):\n",
    "    normalised_test.append(scaler.fit_transform(equalised_test[i]))"
   ],
   "id": "39a82da0b2336f7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "augmented_train = []\n",
    "train_masks_augmented = []\n",
    "\n",
    "for i in range(len(normalised_train)):\n",
    "\n",
    "    # Convert images and masks to numpy arrays\n",
    "    frame = np.array(normalised_train[i])\n",
    "    mask = np.array(resized_train_masks[i])\n",
    "\n",
    "    # Elastic deformation\n",
    "    deformed_frame, deformed_mask = elastic.deform_random_grid([frame, mask])\n",
    "    augmented_train.append(deformed_frame)\n",
    "    augmented_train.append(frame)\n",
    "    train_masks_augmented.append(deformed_mask)\n",
    "    train_masks_augmented.append(mask)\n",
    "\n",
    "    # Rotation (example: 90 degrees)\n",
    "    rotated_frame = rotate(frame, angle=90, mode='wrap')  # Wrap mode handles edges\n",
    "    rotated_mask = rotate(mask, angle=90, mode='wrap')\n",
    "    augmented_train.append(rotated_frame)\n",
    "    train_masks_augmented.append(rotated_mask)\n",
    "\n",
    "    # Horizontal Flip\n",
    "    flipped_frame_h = np.fliplr(frame)  # Horizontal flip\n",
    "    flipped_mask_h = np.fliplr(mask)\n",
    "    augmented_train.append(flipped_frame_h)\n",
    "    train_masks_augmented.append(flipped_mask_h)\n",
    "\n",
    "    # Vertical Flip\n",
    "    flipped_frame_v = np.flipud(frame)  # Vertical flip\n",
    "    flipped_mask_v = np.flipud(mask)\n",
    "    augmented_train.append(flipped_frame_v)\n",
    "    train_masks_augmented.append(flipped_mask_v)\n",
    "\n",
    "    # Combination of Flip and Rotation (e.g., flipped + rotated)\n",
    "    flipped_rotated_frame = rotate(np.fliplr(frame), angle=90, mode='wrap')\n",
    "    flipped_rotated_mask = rotate(np.fliplr(mask), angle=90, mode='wrap')\n",
    "    augmented_train.append(flipped_rotated_frame)\n",
    "    train_masks_augmented.append(flipped_rotated_mask)"
   ],
   "id": "e8d824779d1333c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train = torch.from_numpy(np.array(augmented_train))\n",
    "y_train = torch.from_numpy(np.array(train_masks_augmented))\n",
    "\n",
    "X_test = torch.from_numpy(np.array(normalised_test))\n",
    "X_test = X_test.unsqueeze(1)"
   ],
   "id": "29ea1923d685c52d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Change the dimension order to fit the pytorch format:\n",
    "X_train = X_train.permute(0, 3, 1, 2)\n",
    "y_train = y_train.permute(0, 3, 1, 2)"
   ],
   "id": "1e2363fc78be6050",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_train.shape",
   "id": "796984ad9d8b11c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_temp = y_train.squeeze(1)\n",
    "y_temp.shape"
   ],
   "id": "8e4b8b890c61c4a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Beginning Training')\n",
    "\n",
    "dataset = TensorSegmentationDataset(X_train, y_train)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "pos_weight = calculate_pos_weight(y_temp)\n",
    "del y_temp\n",
    "\n",
    "#loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "loss_fn = BCEWithDiceLoss(pos_weight=pos_weight)\n",
    "\n",
    "trained_unet = train_model(unet, dataloader, loss_fn=loss_fn, num_epochs=30)\n",
    "\n",
    "print('Training Completed')"
   ],
   "id": "80a4e31a1ded31e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.save(trained_unet.state_dict(), \"trained_unet.pth\")",
   "id": "375b5fd0599ba020",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#trained_unet = unet\n",
    "#trained_unet.load_state_dict(torch.load(\"trained_unet.pth\"))"
   ],
   "id": "ed72662064606e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_in_batches(model, dataloader, device='cpu', threshold=0.5):\n",
    "    model = model.to(device)  # Move model to device\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        for batch in dataloader:\n",
    "            # Unpack the batch (assuming no targets)\n",
    "            inputs = batch[0].to(device)  # Only take the input tensor\n",
    "\n",
    "            # Predict\n",
    "            batch_predictions = model(inputs)\n",
    "\n",
    "            # Apply thresholding to convert to binary masks\n",
    "            binary_predictions = (batch_predictions >= threshold).float()  # Convert to binary (0 or 1)\n",
    "\n",
    "            # Store predictions\n",
    "            all_predictions.append(binary_predictions.cpu())  # Move to CPU for storage\n",
    "\n",
    "    # Concatenate all batch predictions into a single tensor\n",
    "    return torch.cat(all_predictions, dim=0)"
   ],
   "id": "795af0e6731842",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = TensorDataset(X_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ],
   "id": "f5f6327608f750c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "binary_masks = predict_in_batches(trained_unet, test_dataloader, threshold=0.7)\n",
    "print('Predictions Calculated')"
   ],
   "id": "20bbfcf0233a6d16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def mask_left_side(tensor, cutoff_column):\n",
    "    tensor[:, :, :cutoff_column] = 0\n",
    "    return tensor"
   ],
   "id": "b7994f8b574d96d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "height, width = 256, 256\n",
    "cutoff_column = width // 2\n",
    "\n",
    "masked_masks = [mask_left_side(mask.clone(), cutoff_column) for mask in binary_masks]"
   ],
   "id": "10375c1d53e3699e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "binary_masks = masked_masks",
   "id": "eac63181e5ea4a9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.save(\"binary_masks.npy\", binary_masks)\n",
    "\n",
    "binary_masks = np.load(\"binary_masks.npy\")"
   ],
   "id": "541bfff1025e8291",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "binary_masks = torch.from_numpy(np.array(binary_masks))\n",
    "binary_masks = binary_masks.permute(0, 2, 3, 1)\n",
    "binary_masks = np.array(binary_masks)\n",
    "binary_masks.shape"
   ],
   "id": "e2f3a07320a4a709",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def quantize_image(tensor, levels=4, min_val=0, max_val=255):\n",
    "\n",
    "    # Find the min and max values of the tensor\n",
    "    min_val, max_val = tensor.min(), tensor.max()\n",
    "\n",
    "    # Compute the step size for quantization\n",
    "    step_size = (max_val - min_val) / (levels - 1)\n",
    "\n",
    "    quantized_tensor = torch.round((tensor - min_val) / step_size) * step_size + min_val\n",
    "\n",
    "    return quantized_tensor"
   ],
   "id": "e14edaf5d9e314e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_test_quantized = quantize_image(X_test, 4)",
   "id": "ce899980e84c26f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "temp = torch.from_numpy(binary_masks)\n",
    "temp = temp.permute(0, 3, 1, 2)"
   ],
   "id": "ad9097091d9e66f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(temp)):\n",
    "    temp_mask = (X_test[i] >= 0.6)\n",
    "    temp_tensor = temp[i]\n",
    "    temp[i] = temp_tensor * temp_mask"
   ],
   "id": "85e08dca451d3170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(3):\n",
    "    #image_tensor = X_test_quantized[i]\n",
    "    image_tensor = X_test[i]\n",
    "    #mask_tensor = binary_masks[i]\n",
    "    mask_tensor = temp[i]\n",
    "\n",
    "    # Prepare the image for display\n",
    "    image_np = image_tensor.permute(1, 2, 0).numpy()  # Convert to (H, W, C)\n",
    "\n",
    "    # Prepare the mask for overlay (ensure it's a NumPy array)\n",
    "    mask_np = mask_tensor.squeeze(0).numpy()\n",
    "\n",
    "    # Plot the image and overlay the mask\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image_np)  # Display the image\n",
    "    plt.imshow(mask_np, cmap=\"jet\", alpha=0.5)  # Overlay the mask with transparency\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()"
   ],
   "id": "206e553d44905e69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "binary_masks = temp",
   "id": "c1d0873b4e10a186",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(binary_masks.shape)\n",
    "binary_masks = binary_masks.permute(0, 2, 3, 1)\n",
    "binary_masks = np.array(binary_masks)\n",
    "binary_masks.shape"
   ],
   "id": "aea1a748cb7cd900",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resized_binary_mask = []\n",
    "\n",
    "for i in range(len(binary_masks)):\n",
    "    current_entry = cv2.resize(binary_masks[i], test_videos[i].shape[:2][::-1], interpolation=cv2.INTER_NEAREST)\n",
    "    #temp = np.array(current_entry)\n",
    "    #temp2 = np.array(test_videos[i])\n",
    "    resized_binary_mask.append(current_entry)\n",
    "\n",
    "del binary_masks"
   ],
   "id": "83ca84025f1088d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "recreated_test_videos = []\n",
    "\n",
    "current_index = 0\n",
    "\n",
    "for i in range(len(name_and_seq)):\n",
    "    name = name_and_seq[i][0]\n",
    "    seq = name_and_seq[i][1]\n",
    "    temp = np.array(resized_binary_mask[current_index:current_index+seq])\n",
    "    current_index += seq\n",
    "    temp = temp.transpose(1, 2, 0)\n",
    "    recreated_test_videos.append(temp)"
   ],
   "id": "bd2a98d2dc0f919e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(789,794):\n",
    "    image_tensor = torch.from_numpy(np.array(test_videos[i]))\n",
    "    mask_tensor = torch.from_numpy(np.array(resized_binary_mask[i]))  # Binary segmentation mask (0s and 1s)\n",
    "    print(mask_tensor.shape)\n",
    "    print(image_tensor.shape)\n",
    "\n",
    "    # Prepare the image for display\n",
    "    image_np = image_tensor#.permute(1, 2, 0).numpy()  # Convert to (H, W, C)\n",
    "\n",
    "    # Prepare the mask for overlay (ensure it's a NumPy array)\n",
    "    mask_np = mask_tensor#.squeeze(0).numpy()\n",
    "\n",
    "    # Plot the image and overlay the mask\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image_np)  # Display the image\n",
    "    plt.imshow(mask_np, cmap=\"jet\", alpha=0.5)  # Overlay the mask with transparency\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()"
   ],
   "id": "299e22a4cb6b92f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#del trained_unet\n",
    "del resized_binary_mask"
   ],
   "id": "ae8adbce93130a93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flattened_masks = []\n",
    "\n",
    "for item in recreated_test_videos:\n",
    "    flattened = item.flatten()\n",
    "    flattened_masks.append(flattened)"
   ],
   "id": "8154e13c987be97b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_sequences(arr):\n",
    "    first_indices, last_indices, lengths = [], [], []\n",
    "    n, i = len(arr), 0\n",
    "    arr = [0] + list(arr) + [0]\n",
    "    for index, value in enumerate(arr[:-1]):\n",
    "        if arr[index+1]-arr[index] == 1:\n",
    "            first_indices.append(index)\n",
    "        if arr[index+1]-arr[index] == -1:\n",
    "            last_indices.append(index)\n",
    "    lengths = list(np.array(last_indices)-np.array(first_indices))\n",
    "    return first_indices, lengths"
   ],
   "id": "9cdcef0253d36ad6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "index_length = []\n",
    "\n",
    "for array in flattened_masks:\n",
    "    first_indices, lengths = get_sequences(array)\n",
    "    index_length.append((first_indices, lengths))\n",
    "\n",
    "print('index_length sequences calculated')"
   ],
   "id": "8e18fac85b476c6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"index_length.txt\", \"w\") as file:\n",
    "    for item in index_length:\n",
    "        file.write(f\"{item}\\n\")"
   ],
   "id": "f09e908230707117",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "submission = []\n",
    "\n",
    "for video_mask, (video_name, _) in zip(index_length, name_and_seq):\n",
    "    indices = video_mask[0]\n",
    "    lengths = video_mask[1]\n",
    "    for i in range(len(video_mask[0])):\n",
    "        pair = [indices[i], lengths[i]]\n",
    "        name = video_name + \"_\" + str(i)\n",
    "        submission.append((name, pair))"
   ],
   "id": "9a11800251ebd4a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "submission",
   "id": "ee4c37deaf23a217",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_to_save = []\n",
    "ids_to_save = []\n",
    "\n",
    "for name, info in submission:\n",
    "    ids_to_save.append(name)\n",
    "    y_pred_to_save.append(info)"
   ],
   "id": "ae977eb6dc45a34c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"id\":ids_to_save, \"value\":[list(map(int, minili)) for minili in y_pred_to_save]})\n",
    "df.to_csv(f\"mysubmissionfile.csv\", index=False)"
   ],
   "id": "2edb3be0ee49c0e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b7e498d06bb6f823",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
